{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Synanthropic/reading-analog-gauge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unoptimized for mac m1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import atan2, degrees\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self):\n",
    "        self.input_shape = (224, 224, 3)\n",
    "        self.min_value = 0\n",
    "        self.max_value = 10\n",
    "        \n",
    "    def build_model(self):\n",
    "        # Modified model architecture to predict single value\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=self.input_shape),\n",
    "            tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1)  # Single output for gauge reading\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        # Load dataset from HuggingFace\n",
    "        print(\"Loading dataset...\")\n",
    "        dataset = load_dataset(\"Synanthropic/reading-analog-gauge\")\n",
    "        train_ds = dataset['train']\n",
    "        \n",
    "        def preprocess_single_example(example):\n",
    "            # Convert image to numpy array\n",
    "            image = np.array(example['image'])\n",
    "            \n",
    "            # Resize image\n",
    "            image = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "            \n",
    "            # Normalize image\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Get label\n",
    "            label = np.array(example['label'], dtype=np.float32)\n",
    "            \n",
    "            return {\n",
    "                'image': image,\n",
    "                'label': label\n",
    "            }\n",
    "        \n",
    "        print(\"Processing examples...\")\n",
    "        # Process all examples\n",
    "        processed_data = [preprocess_single_example(example) for example in train_ds]\n",
    "        \n",
    "        # Separate images and labels\n",
    "        images = np.array([example['image'] for example in processed_data])\n",
    "        labels = np.array([example['label'] for example in processed_data])\n",
    "        \n",
    "        print(f\"Dataset shape - Images: {images.shape}, Labels: {labels.shape}\")\n",
    "        \n",
    "        # Create TensorFlow dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        \n",
    "        # Batch and shuffle\n",
    "        dataset = dataset.shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    def train_model(self, epochs=10):\n",
    "        # Build model\n",
    "        model = self.build_model()\n",
    "        \n",
    "        print(\"Preparing dataset...\")\n",
    "        train_ds = self.prepare_dataset()\n",
    "        print(\"Dataset prepared successfully!\")\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Starting training...\")\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='loss',\n",
    "                    patience=3,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='loss',\n",
    "                    factor=0.5,\n",
    "                    patience=2\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "\n",
    "    def convert_to_tflite(self, model):\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite_model = converter.convert()\n",
    "        return tflite_model\n",
    "\n",
    "    def save_model(self, tflite_model, model_path):\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(tflite_model, f)\n",
    "    \n",
    "    def predict_value(self, model, image_path):\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        image = np.expand_dims(image, 0)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = model.predict(image)\n",
    "        return float(prediction[0][0])\n",
    "\n",
    "    def visualize_prediction(self, image_path, prediction):\n",
    "        # Load and resize image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Predicted Value: {prediction:.2f}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # Initialize GaugeReader\n",
    "    gauge_reader = GaugeReader()\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model, history = gauge_reader.train_model(epochs=10)\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    print(\"Converting to TFLite...\")\n",
    "    tflite_model = gauge_reader.convert_to_tflite(model)\n",
    "    \n",
    "    # Save model\n",
    "    print(\"Saving model...\")\n",
    "    gauge_reader.save_model(tflite_model, 'gauge_reader_model.tflite')\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='MAE')\n",
    "    plt.title('Model MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "dataset = load_dataset(\"Synanthropic/reading-analog-gauge\")\n",
    "train_ds = dataset['train']\n",
    "example = train_ds[0]\n",
    "print(\"Dataset keys:\", example.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for mac m1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: training_checkpoints/epoch_04.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 18:28:27.455764: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-30 18:28:27.455783: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-30 18:28:27.455786: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-30 18:28:27.455821: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-30 18:28:27.455835: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from previous checkpoint...\n",
      "Converting to TFLite...\n",
      "Converting to TFLite format...\n",
      "INFO:tensorflow:Assets written to: /var/folders/rt/0x35vmdd32ldd69_8j6wrvgc0000gn/T/tmp1s0ea92r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/rt/0x35vmdd32ldd69_8j6wrvgc0000gn/T/tmp1s0ea92r/assets\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import atan2, degrees\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Garbage collector\n",
    "import os\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self):\n",
    "        self.input_shape = (160, 160, 3)\n",
    "        self.min_value = 0\n",
    "        self.max_value = 10\n",
    "        self.batch_size = 16\n",
    "        self.checkpoint_dir = 'training_checkpoints'\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=self.input_shape),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        print(\"Loading dataset...\")\n",
    "        dataset = load_dataset(\n",
    "            \"Synanthropic/reading-analog-gauge\",\n",
    "            split='train'\n",
    "        )\n",
    "        \n",
    "        print(f\"Total examples in dataset: {len(dataset)}\")\n",
    "        \n",
    "        def preprocess_example(example):\n",
    "            # Load and resize image\n",
    "            image = np.array(example['image'])\n",
    "            image = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            label = float(example['label'])\n",
    "            return image, label\n",
    "\n",
    "        def generator():\n",
    "            for example in dataset:\n",
    "                image, label = preprocess_example(example)\n",
    "                yield image, label\n",
    "\n",
    "        tf_dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=self.input_shape, dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        tf_dataset = tf_dataset.shuffle(1000)\n",
    "        tf_dataset = tf_dataset.batch(self.batch_size)\n",
    "        tf_dataset = tf_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        steps_per_epoch = len(dataset) // self.batch_size\n",
    "\n",
    "        return tf_dataset, steps_per_epoch\n",
    "\n",
    "    def train_model(self, epochs=10):\n",
    "        # Build model\n",
    "        model = self.build_model()\n",
    "        \n",
    "        print(\"Preparing dataset...\")\n",
    "        train_ds, steps_per_epoch = self.prepare_dataset()\n",
    "        print(f\"Dataset prepared successfully! Steps per epoch: {steps_per_epoch}\")\n",
    "        \n",
    "        # Define checkpoint paths with .keras extension\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, \"epoch_{epoch:02d}.keras\")\n",
    "        best_model_path = os.path.join(self.checkpoint_dir, \"best_model.keras\")\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Starting training...\")\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            callbacks=[\n",
    "                # Save after every epoch\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath=checkpoint_path,\n",
    "                    save_weights_only=False,\n",
    "                    save_freq='epoch'\n",
    "                ),\n",
    "                # Save best model based on loss\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath=best_model_path,\n",
    "                    save_best_only=True,\n",
    "                    monitor='loss',\n",
    "                    mode='min',\n",
    "                    save_weights_only=False\n",
    "                ),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='loss',\n",
    "                    patience=3,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='loss',\n",
    "                    factor=0.5,\n",
    "                    patience=2\n",
    "                ),\n",
    "                # Memory cleanup callback\n",
    "                tf.keras.callbacks.LambdaCallback(\n",
    "                    on_epoch_end=lambda epoch, logs: gc.collect()\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "\n",
    "    def load_latest_checkpoint(self):\n",
    "        \"\"\"Load the latest checkpoint if it exists.\"\"\"\n",
    "        checkpoints = [d for d in os.listdir(self.checkpoint_dir) \n",
    "                      if d.startswith('epoch_') and d.endswith('.keras')]\n",
    "        if not checkpoints:\n",
    "            return None\n",
    "            \n",
    "        latest_checkpoint = max(checkpoints)\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, latest_checkpoint)\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        return tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "    def convert_to_tflite(self, model):\n",
    "        print(\"Converting to TFLite format...\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        return tflite_model\n",
    "\n",
    "    def save_model(self, tflite_model, model_path):\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(tflite_model, f)\n",
    "\n",
    "def main():\n",
    "    # Initialize GaugeReader\n",
    "    gauge_reader = GaugeReader()\n",
    "    \n",
    "    try:\n",
    "        # Check for existing checkpoints\n",
    "        existing_model = gauge_reader.load_latest_checkpoint()\n",
    "        if existing_model:\n",
    "            print(\"Resuming from previous checkpoint...\")\n",
    "            model = existing_model\n",
    "        else:\n",
    "            # Train model\n",
    "            print(\"Training new model...\")\n",
    "            model, history = gauge_reader.train_model(epochs=10)\n",
    "        \n",
    "        # Convert to TFLite\n",
    "        print(\"Converting to TFLite...\")\n",
    "        tflite_model = gauge_reader.convert_to_tflite(model)\n",
    "        \n",
    "        # Save model\n",
    "        print(\"Saving model...\")\n",
    "        gauge_reader.save_model(tflite_model, 'gauge_reader_model.tflite')\n",
    "        \n",
    "        # Plot training history if available\n",
    "        if 'history' in locals():\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['loss'], label='Loss')\n",
    "            plt.title('Model Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['mae'], label='MAE')\n",
    "            plt.title('Model MAE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        # Clean up memory in case of error\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15670774299620544029\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 13422472795634595793\n",
      "physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 18:30:26.618328: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-30 18:30:26.618445: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-30 18:30:26.618497: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-30 18:30:26.618562: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-30 18:30:26.618591: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimized for RTX 3060 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faizal/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "I0000 00:00:1735302132.971772    6181 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9812 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-12-27 17:52:28.489984: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-12-27 17:52:28.490012: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2024-12-27 17:52:28.490036: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1006] Profiler found 1 GPUs\n",
      "2024-12-27 17:52:28.518519: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2024-12-27 17:52:28.518593: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1213] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:52:40.442151: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 5 of 1000\n",
      "2024-12-27 17:52:50.781367: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 12 of 1000\n",
      "2024-12-27 17:53:10.919037: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 26 of 1000\n",
      "2024-12-27 17:53:21.097728: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 33 of 1000\n",
      "2024-12-27 17:53:40.070189: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 46 of 1000\n",
      "2024-12-27 17:53:50.271973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 53 of 1000\n",
      "2024-12-27 17:54:10.366805: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 67 of 1000\n",
      "2024-12-27 17:54:20.535547: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 74 of 1000\n",
      "2024-12-27 17:54:30.954686: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 81 of 1000\n",
      "2024-12-27 17:54:49.909448: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 94 of 1000\n",
      "2024-12-27 17:54:59.961857: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 101 of 1000\n",
      "2024-12-27 17:55:10.522451: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 108 of 1000\n",
      "2024-12-27 17:55:20.930991: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 115 of 1000\n",
      "2024-12-27 17:55:40.111009: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 128 of 1000\n",
      "2024-12-27 17:56:00.705562: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 141 of 1000\n",
      "2024-12-27 17:56:20.980760: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 154 of 1000\n",
      "2024-12-27 17:56:40.447819: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 167 of 1000\n",
      "2024-12-27 17:56:50.757620: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 174 of 1000\n",
      "2024-12-27 17:57:11.022599: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 187 of 1000\n",
      "2024-12-27 17:57:30.250619: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 200 of 1000\n",
      "2024-12-27 17:57:40.481569: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 207 of 1000\n",
      "2024-12-27 17:57:59.751572: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 220 of 1000\n",
      "2024-12-27 17:58:10.319620: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 227 of 1000\n",
      "2024-12-27 17:58:20.659600: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 234 of 1000\n",
      "2024-12-27 17:58:30.675540: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 241 of 1000\n",
      "2024-12-27 17:58:49.964158: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 254 of 1000\n",
      "2024-12-27 17:59:00.728770: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 261 of 1000\n",
      "2024-12-27 17:59:21.256831: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 275 of 1000\n",
      "2024-12-27 17:59:39.847306: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 288 of 1000\n",
      "2024-12-27 17:59:49.937508: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 295 of 1000\n",
      "2024-12-27 18:00:00.588175: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 302 of 1000\n",
      "2024-12-27 18:00:20.947135: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 316 of 1000\n",
      "2024-12-27 18:00:40.292238: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 329 of 1000\n",
      "2024-12-27 18:00:50.657190: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 336 of 1000\n",
      "2024-12-27 18:01:00.875982: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 343 of 1000\n",
      "2024-12-27 18:01:20.759666: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 356 of 1000\n",
      "2024-12-27 18:01:30.777229: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 363 of 1000\n",
      "2024-12-27 18:01:50.062726: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 376 of 1000\n",
      "2024-12-27 18:02:00.237302: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 383 of 1000\n",
      "2024-12-27 18:02:10.334077: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 390 of 1000\n",
      "2024-12-27 18:02:29.967165: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 403 of 1000\n",
      "2024-12-27 18:02:40.934751: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 410 of 1000\n",
      "2024-12-27 18:02:51.178028: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 417 of 1000\n",
      "2024-12-27 18:03:10.011751: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 430 of 1000\n",
      "2024-12-27 18:03:20.350509: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 437 of 1000\n",
      "2024-12-27 18:03:30.897857: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 444 of 1000\n",
      "2024-12-27 18:03:41.044854: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 451 of 1000\n",
      "2024-12-27 18:04:00.727843: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 465 of 1000\n",
      "2024-12-27 18:04:10.892536: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 472 of 1000\n",
      "2024-12-27 18:04:30.350212: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 485 of 1000\n",
      "2024-12-27 18:04:40.666088: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 492 of 1000\n",
      "2024-12-27 18:05:01.084539: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 506 of 1000\n",
      "2024-12-27 18:05:19.734947: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 519 of 1000\n",
      "2024-12-27 18:05:30.040025: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 526 of 1000\n",
      "2024-12-27 18:05:40.435028: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 533 of 1000\n",
      "2024-12-27 18:06:01.048881: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 547 of 1000\n",
      "2024-12-27 18:06:19.872122: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 560 of 1000\n",
      "2024-12-27 18:06:30.611937: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 567 of 1000\n",
      "2024-12-27 18:06:50.350934: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 580 of 1000\n",
      "2024-12-27 18:07:00.615981: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 587 of 1000\n",
      "2024-12-27 18:07:10.995175: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 594 of 1000\n",
      "2024-12-27 18:07:29.980841: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 607 of 1000\n",
      "2024-12-27 18:07:40.558807: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 614 of 1000\n",
      "2024-12-27 18:07:50.793371: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 621 of 1000\n",
      "2024-12-27 18:08:09.740018: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 634 of 1000\n",
      "2024-12-27 18:08:19.923540: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 641 of 1000\n",
      "2024-12-27 18:08:30.094467: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 648 of 1000\n",
      "2024-12-27 18:08:40.552793: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 655 of 1000\n",
      "2024-12-27 18:08:50.892290: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 662 of 1000\n",
      "2024-12-27 18:09:10.936570: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 676 of 1000\n",
      "2024-12-27 18:09:21.399541: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 683 of 1000\n",
      "2024-12-27 18:09:40.021804: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 696 of 1000\n",
      "2024-12-27 18:09:50.310958: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 703 of 1000\n",
      "2024-12-27 18:10:10.682837: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 717 of 1000\n",
      "2024-12-27 18:10:20.722041: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 724 of 1000\n",
      "2024-12-27 18:10:39.845169: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 737 of 1000\n",
      "2024-12-27 18:10:50.452433: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 744 of 1000\n",
      "2024-12-27 18:11:00.967267: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 751 of 1000\n",
      "2024-12-27 18:11:20.667611: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 764 of 1000\n",
      "2024-12-27 18:11:40.166634: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 777 of 1000\n",
      "2024-12-27 18:11:50.974814: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 784 of 1000\n",
      "2024-12-27 18:12:09.911318: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 797 of 1000\n",
      "2024-12-27 18:12:20.736334: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 804 of 1000\n",
      "2024-12-27 18:12:39.896015: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 816 of 1000\n",
      "2024-12-27 18:12:51.126948: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 823 of 1000\n",
      "2024-12-27 18:13:10.804458: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 836 of 1000\n",
      "2024-12-27 18:13:29.947014: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 849 of 1000\n",
      "2024-12-27 18:13:40.291288: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 856 of 1000\n",
      "2024-12-27 18:13:51.185414: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 863 of 1000\n",
      "2024-12-27 18:14:10.829109: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 876 of 1000\n",
      "2024-12-27 18:14:20.997529: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 883 of 1000\n",
      "2024-12-27 18:14:39.741438: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 895 of 1000\n",
      "2024-12-27 18:14:49.912585: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 902 of 1000\n",
      "2024-12-27 18:15:00.342512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 909 of 1000\n",
      "2024-12-27 18:15:10.474428: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 916 of 1000\n",
      "2024-12-27 18:15:30.697206: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 929 of 1000\n",
      "2024-12-27 18:15:50.660900: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 942 of 1000\n",
      "2024-12-27 18:16:00.976177: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 949 of 1000\n",
      "2024-12-27 18:16:20.566677: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 962 of 1000\n",
      "2024-12-27 18:16:30.887622: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 969 of 1000\n",
      "2024-12-27 18:16:50.319250: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 982 of 1000\n",
      "2024-12-27 18:17:00.674532: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 989 of 1000\n",
      "2024-12-27 18:17:11.027697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:4: Filling up shuffle buffer (this may take a while): 996 of 1000\n",
      "2024-12-27 18:17:16.816220: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735303682.662298    7506 service.cc:148] XLA service 0x778d3c003460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735303682.663560    7506 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-12-27 18:18:02.716982: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1735303682.862111    7506 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-27 18:18:03.886968: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1055', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-12-27 18:18:03.994284: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1055', 60 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-12-27 18:18:04.048027: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1055', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown \u001b[1m1539s\u001b[0m 1539s/step - loss: 0.0012 - mae: 0.0280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735303687.475291    7506 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     63/Unknown \u001b[1m4542s\u001b[0m 48s/step - loss: 0.0024 - mae: 0.0211"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 183\u001b[0m\n\u001b[1;32m    180\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 160\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    159\u001b[0m     gauge_reader \u001b[38;5;241m=\u001b[39m GaugeReader()\n\u001b[0;32m--> 160\u001b[0m     model, history \u001b[38;5;241m=\u001b[39m \u001b[43mgauge_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     tflite_model \u001b[38;5;241m=\u001b[39m gauge_reader\u001b[38;5;241m.\u001b[39mconvert_to_tflite(model)\n\u001b[1;32m    162\u001b[0m     gauge_reader\u001b[38;5;241m.\u001b[39msave_model(tflite_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgauge_reader_model.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 125\u001b[0m, in \u001b[0;36mGaugeReader.train_model\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Add TensorBoard callback for memory monitoring\u001b[39;00m\n\u001b[1;32m    120\u001b[0m tensorboard_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(\n\u001b[1;32m    121\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    122\u001b[0m     profile_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m500,520\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Profile a few batches\u001b[39;00m\n\u001b[1;32m    123\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/work/gnprc-domi-app/tf/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import atan2, degrees\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self):\n",
    "        self.input_shape = (160, 160, 3)  # Reduced input size\n",
    "        self.min_value = 0\n",
    "        self.max_value = 10\n",
    "        self.batch_size = 32  # Smaller batch size to reduce memory\n",
    "\n",
    "    def build_model(self):\n",
    "        # Lighter model architecture with fewer parameters\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=self.input_shape),\n",
    "            \n",
    "            # First conv block - reduced filters\n",
    "            tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            # Second conv block\n",
    "            tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            # Third conv block\n",
    "            tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            # Fourth conv block\n",
    "            tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            \n",
    "            # Reduced dense layers\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        print(\"Loading dataset...\")\n",
    "        # Load dataset in streaming mode\n",
    "        dataset = load_dataset(\n",
    "            \"Synanthropic/reading-analog-gauge\",\n",
    "            streaming=True\n",
    "        )\n",
    "        train_ds = dataset['train']\n",
    "        \n",
    "        def preprocess_example(example):\n",
    "            image = np.array(example['image'])\n",
    "            image = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "            image = (image.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "            return image, example['label']\n",
    "        \n",
    "        # Create streaming datasets with generators\n",
    "        def generate_examples(split):\n",
    "            for example in split:\n",
    "                yield preprocess_example(example)\n",
    "        \n",
    "        # Calculate approximate sizes\n",
    "        total_size = 10000  # Approximate dataset size\n",
    "        val_size = int(0.1 * total_size)\n",
    "        \n",
    "        # Create datasets using from_generator\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: generate_examples(train_ds.take(total_size - val_size)),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=self.input_shape, dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        val_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: generate_examples(train_ds.skip(total_size - val_size).take(val_size)),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=self.input_shape, dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Optimize for performance while maintaining memory efficiency\n",
    "        train_dataset = (train_dataset\n",
    "            .shuffle(1000)  # Reduced buffer size\n",
    "            .batch(self.batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        \n",
    "        val_dataset = (val_dataset\n",
    "            .batch(self.batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    def train_model(self, epochs=20):\n",
    "        # Configure memory growth\n",
    "        for device in tf.config.list_physical_devices('GPU'):\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        \n",
    "        model = self.build_model()\n",
    "        train_ds, val_ds = self.prepare_dataset()\n",
    "        \n",
    "        # Add TensorBoard callback for memory monitoring\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs',\n",
    "            profile_batch='500,520'  # Profile a few batches\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=3,\n",
    "                    min_lr=1e-6\n",
    "                ),\n",
    "                tensorboard_callback\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "\n",
    "    def convert_to_tflite(self, model):\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]  # Use FP16 quantization\n",
    "        tflite_model = converter.convert()\n",
    "        return tflite_model\n",
    "\n",
    "    def save_model(self, tflite_model, model_path):\n",
    "        with open(model_path, 'wb') as f:\n",
    "            f.write(tflite_model)  # Save directly without pickle\n",
    "\n",
    "def main():\n",
    "    gauge_reader = GaugeReader()\n",
    "    model, history = gauge_reader.train_model(epochs=20)\n",
    "    tflite_model = gauge_reader.convert_to_tflite(model)\n",
    "    gauge_reader.save_model(tflite_model, 'gauge_reader_model.tflite')\n",
    "    \n",
    "    # Plot with reduced memory usage\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Train')\n",
    "    plt.plot(history.history['val_mae'], label='Val')\n",
    "    plt.title('MAE')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:51:51.975267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735302112.075544    6181 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735302112.103413    6181 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-27 17:51:52.359926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 19:12:05.432159: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-12-27 19:12:05.432183: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2024-12-27 19:12:05.437055: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2024-12-27 19:12:05.440574: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1213] CUPTI activity buffer flushed\n",
      "2024-12-27 19:12:17.525228: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 4 of 1000\n",
      "2024-12-27 19:12:27.841763: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 11 of 1000\n",
      "2024-12-27 19:12:48.472231: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 24 of 1000\n",
      "2024-12-27 19:13:08.577519: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 38 of 1000\n",
      "2024-12-27 19:13:18.655258: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 45 of 1000\n",
      "2024-12-27 19:13:38.265266: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 59 of 1000\n",
      "2024-12-27 19:13:58.126536: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 73 of 1000\n",
      "2024-12-27 19:14:17.911111: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 87 of 1000\n",
      "2024-12-27 19:14:37.813333: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 101 of 1000\n",
      "2024-12-27 19:14:58.165011: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 115 of 1000\n",
      "2024-12-27 19:15:17.585664: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 128 of 1000\n",
      "2024-12-27 19:15:27.624797: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 135 of 1000\n",
      "2024-12-27 19:15:37.769140: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 142 of 1000\n",
      "2024-12-27 19:15:48.099488: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 149 of 1000\n",
      "2024-12-27 19:15:58.307885: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 156 of 1000\n",
      "2024-12-27 19:16:18.515626: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 170 of 1000\n",
      "2024-12-27 19:16:38.022638: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 183 of 1000\n",
      "2024-12-27 19:16:57.427462: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 196 of 1000\n",
      "2024-12-27 19:17:07.483941: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 203 of 1000\n",
      "2024-12-27 19:17:18.074141: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 210 of 1000\n",
      "2024-12-27 19:17:28.167788: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 217 of 1000\n",
      "2024-12-27 19:17:38.330762: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 224 of 1000\n",
      "2024-12-27 19:17:58.577432: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 238 of 1000\n",
      "2024-12-27 19:18:08.685014: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 245 of 1000\n",
      "2024-12-27 19:18:27.825966: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 258 of 1000\n",
      "2024-12-27 19:18:47.999546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 271 of 1000\n",
      "2024-12-27 19:18:58.318701: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 278 of 1000\n",
      "2024-12-27 19:19:08.627407: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 285 of 1000\n",
      "2024-12-27 19:19:27.812940: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 298 of 1000\n",
      "2024-12-27 19:19:47.320234: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 311 of 1000\n",
      "2024-12-27 19:19:58.156223: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 318 of 1000\n",
      "2024-12-27 19:20:08.334868: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 325 of 1000\n",
      "2024-12-27 19:20:27.581235: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 338 of 1000\n",
      "2024-12-27 19:20:38.231041: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 345 of 1000\n",
      "2024-12-27 19:20:48.386973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 352 of 1000\n",
      "2024-12-27 19:20:58.492281: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 359 of 1000\n",
      "2024-12-27 19:21:17.829441: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 372 of 1000\n",
      "2024-12-27 19:21:27.955217: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 379 of 1000\n",
      "2024-12-27 19:21:38.532496: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 386 of 1000\n",
      "2024-12-27 19:21:58.030562: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 399 of 1000\n",
      "2024-12-27 19:22:18.140162: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 412 of 1000\n",
      "2024-12-27 19:22:38.289120: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 425 of 1000\n",
      "2024-12-27 19:22:57.654225: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 438 of 1000\n",
      "2024-12-27 19:23:08.026678: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 444 of 1000\n",
      "2024-12-27 19:23:18.506164: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 451 of 1000\n",
      "2024-12-27 19:23:37.964591: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 464 of 1000\n",
      "2024-12-27 19:23:48.197451: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 471 of 1000\n",
      "2024-12-27 19:23:58.842600: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 478 of 1000\n",
      "2024-12-27 19:24:18.554688: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 491 of 1000\n",
      "2024-12-27 19:24:38.296821: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 504 of 1000\n",
      "2024-12-27 19:24:57.425562: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 517 of 1000\n",
      "2024-12-27 19:25:17.440316: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 530 of 1000\n",
      "2024-12-27 19:25:27.685473: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 537 of 1000\n",
      "2024-12-27 19:25:38.479062: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 544 of 1000\n",
      "2024-12-27 19:25:57.702057: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 557 of 1000\n",
      "2024-12-27 19:26:18.170926: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 571 of 1000\n",
      "2024-12-27 19:26:28.587801: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 578 of 1000\n",
      "2024-12-27 19:26:48.783294: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 592 of 1000\n",
      "2024-12-27 19:27:07.805560: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 605 of 1000\n",
      "2024-12-27 19:27:18.037788: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 612 of 1000\n",
      "2024-12-27 19:27:37.916965: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 626 of 1000\n",
      "2024-12-27 19:27:49.007054: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 632 of 1000\n",
      "2024-12-27 19:28:08.965410: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 645 of 1000\n",
      "2024-12-27 19:28:27.898994: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 658 of 1000\n",
      "2024-12-27 19:28:38.312575: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 665 of 1000\n",
      "2024-12-27 19:28:57.558557: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 678 of 1000\n",
      "2024-12-27 19:29:08.306490: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 685 of 1000\n",
      "2024-12-27 19:29:18.398272: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 692 of 1000\n",
      "2024-12-27 19:29:28.398088: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 699 of 1000\n",
      "2024-12-27 19:29:48.127869: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 712 of 1000\n",
      "2024-12-27 19:29:58.195220: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 719 of 1000\n",
      "2024-12-27 19:30:17.374556: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 732 of 1000\n",
      "2024-12-27 19:30:28.014082: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 739 of 1000\n",
      "2024-12-27 19:30:48.248958: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 753 of 1000\n",
      "2024-12-27 19:31:07.950694: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 765 of 1000\n",
      "2024-12-27 19:31:18.272596: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 772 of 1000\n",
      "2024-12-27 19:31:37.361429: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 785 of 1000\n",
      "2024-12-27 19:31:47.679399: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 792 of 1000\n",
      "2024-12-27 19:31:58.535595: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 799 of 1000\n",
      "2024-12-27 19:32:08.715679: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 806 of 1000\n",
      "2024-12-27 19:32:27.853592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 819 of 1000\n",
      "2024-12-27 19:32:38.288897: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 826 of 1000\n",
      "2024-12-27 19:32:57.624119: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 839 of 1000\n",
      "2024-12-27 19:33:18.111317: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 853 of 1000\n",
      "2024-12-27 19:33:28.317711: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 860 of 1000\n",
      "2024-12-27 19:33:38.470892: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 867 of 1000\n",
      "2024-12-27 19:33:57.826393: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 880 of 1000\n",
      "2024-12-27 19:34:08.527985: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 887 of 1000\n",
      "2024-12-27 19:34:27.536080: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 899 of 1000\n",
      "2024-12-27 19:34:37.964392: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 906 of 1000\n",
      "2024-12-27 19:34:48.326970: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 913 of 1000\n",
      "2024-12-27 19:35:07.535071: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 925 of 1000\n",
      "2024-12-27 19:35:17.865096: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 932 of 1000\n",
      "2024-12-27 19:35:28.530710: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 939 of 1000\n",
      "2024-12-27 19:35:47.798661: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 952 of 1000\n",
      "2024-12-27 19:35:58.569758: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 959 of 1000\n",
      "2024-12-27 19:36:17.657297: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 972 of 1000\n",
      "2024-12-27 19:36:27.786277: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 979 of 1000\n",
      "2024-12-27 19:36:38.204973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 986 of 1000\n",
      "2024-12-27 19:36:48.307121: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:19: Filling up shuffle buffer (this may take a while): 993 of 1000\n",
      "2024-12-27 19:36:58.184251: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11/Unknown \u001b[1m2565s\u001b[0m 97s/step - loss: 2.6546 - mae: 1.1359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 01e050d6-887c-4282-a4c1-2fb05ea4c2a4)')' thrown while requesting GET https://huggingface.co/datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7788333d4200>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 1a075cb6-9d14-46ac-9005-ab8914b3560c)')' thrown while requesting GET https://huggingface.co/datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7789274faae0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: da3da7a1-fc95-4a8f-83ef-b142c4919424)')' thrown while requesting GET https://huggingface.co/datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x77897b3f4b60>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 77dc11ab-5748-48d0-bfbf-ac903436d3cc)')' thrown while requesting GET https://huggingface.co/datasets/Synanthropic/reading-analog-gauge/resolve/f9b31b44c9a693eddcc9c93a247ad30c3005ea07/corners.zip\n",
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31/Unknown \u001b[1m4583s\u001b[0m 100s/step - loss: 1.6418 - mae: 0.8470"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self):\n",
    "        self.input_shape = (160, 160, 3)\n",
    "        self.min_value = 0\n",
    "        self.max_value = 10\n",
    "        self.batch_size = 64  # Increased but still conservative for 12GB VRAM\n",
    "        \n",
    "        # Enable mixed precision for better memory efficiency\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=self.input_shape),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        print(\"Loading dataset...\")\n",
    "        dataset = load_dataset(\n",
    "            \"Synanthropic/reading-analog-gauge\",\n",
    "            streaming=True\n",
    "        )\n",
    "        train_ds = dataset['train']\n",
    "        \n",
    "        @tf.function\n",
    "        def preprocess_image(image):\n",
    "            image = tf.image.resize(image, [self.input_shape[0], self.input_shape[1]])\n",
    "            image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "            return image\n",
    "\n",
    "        def generate_examples(split):\n",
    "            for example in split:\n",
    "                # Convert PIL image to numpy array\n",
    "                image = np.array(example['image'])\n",
    "                # Convert to tensor and preprocess\n",
    "                image = preprocess_image(image)\n",
    "                yield image, example['label']\n",
    "\n",
    "        # Calculate sizes\n",
    "        total_size = 10000\n",
    "        val_size = int(0.1 * total_size)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: generate_examples(train_ds.take(total_size - val_size)),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=self.input_shape, dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        val_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: generate_examples(train_ds.skip(total_size - val_size).take(val_size)),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=self.input_shape, dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Optimize the input pipeline\n",
    "        train_dataset = (train_dataset\n",
    "            .cache()  # Cache after preprocessing\n",
    "            .shuffle(1000)\n",
    "            .batch(self.batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        \n",
    "        val_dataset = (val_dataset\n",
    "            .batch(self.batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    def train_model(self, epochs=20):\n",
    "        # Configure GPU memory growth\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        model = self.build_model()\n",
    "        train_ds, val_ds = self.prepare_dataset()\n",
    "        \n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs',\n",
    "            profile_batch='100,120'\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=3,\n",
    "                    min_lr=1e-6\n",
    "                ),\n",
    "                tensorboard_callback\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "\n",
    "    def convert_to_tflite(self, model):\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        tflite_model = converter.convert()\n",
    "        return tflite_model\n",
    "\n",
    "    def save_model(self, tflite_model, model_path):\n",
    "        with open(model_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "def main():\n",
    "    gauge_reader = GaugeReader()\n",
    "    model, history = gauge_reader.train_model(epochs=20)\n",
    "    tflite_model = gauge_reader.convert_to_tflite(model)\n",
    "    gauge_reader.save_model(tflite_model, 'gauge_reader_model.tflite')\n",
    "    \n",
    "    # Plot with reduced memory usage\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Train')\n",
    "    plt.plot(history.history['val_mae'], label='Val')\n",
    "    plt.title('MAE')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on roboflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "class GaugeReaderYOLO:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def update_yaml_paths(self, data_yaml_path):\n",
    "        \"\"\"Update data.yaml with correct absolute paths\"\"\"\n",
    "        # Get the dataset root directory\n",
    "        dataset_dir = Path(data_yaml_path).parent\n",
    "        \n",
    "        # Read existing yaml\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            data_yaml = yaml.safe_load(f)\n",
    "        \n",
    "        # Update paths with absolute paths\n",
    "        data_yaml['path'] = str(dataset_dir.absolute())\n",
    "        data_yaml['train'] = str((dataset_dir / 'train' / 'images').absolute())\n",
    "        data_yaml['val'] = str((dataset_dir / 'valid' / 'images').absolute())\n",
    "        \n",
    "        # Verify paths exist\n",
    "        for path_key in ['train', 'val']:\n",
    "            path = Path(data_yaml[path_key])\n",
    "            if not path.exists():\n",
    "                raise FileNotFoundError(f\"Path {path} does not exist!\")\n",
    "        \n",
    "        # Save updated yaml\n",
    "        updated_yaml_path = dataset_dir / 'updated_data.yaml'\n",
    "        with open(updated_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_yaml, f)\n",
    "            \n",
    "        return str(updated_yaml_path)\n",
    "    \n",
    "    def train(self, data_yaml_path, epochs=50):\n",
    "        \"\"\"Train YOLOv8 model\"\"\"\n",
    "        # Update yaml paths\n",
    "        print(\"Updating dataset paths...\")\n",
    "        updated_yaml_path = self.update_yaml_paths(data_yaml_path)\n",
    "        \n",
    "        print(f\"Training with dataset config: {updated_yaml_path}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = YOLO('yolov8n.pt')  # use YOLOv8 nano model\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            self.model.train(\n",
    "                data=updated_yaml_path,\n",
    "                epochs=epochs,\n",
    "                imgsz=640,\n",
    "                batch=16,\n",
    "                device=0,  # Use GPU\n",
    "                patience=10,  # Early stopping\n",
    "                save=True,\n",
    "                project='gauge_detection'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {str(e)}\")\n",
    "            # Print the content of the yaml file for debugging\n",
    "            with open(updated_yaml_path, 'r') as f:\n",
    "                print(\"\\nDataset YAML contents:\")\n",
    "                print(f.read())\n",
    "            raise\n",
    "            \n",
    "    def calculate_angle(self, center, needle_tip):\n",
    "        \"\"\"Calculate angle between vertical line and needle\"\"\"\n",
    "        dx = needle_tip[0] - center[0]\n",
    "        dy = needle_tip[1] - center[1]\n",
    "        angle = math.degrees(math.atan2(dy, dx))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "        return angle\n",
    "\n",
    "    def get_reading_from_angle(self, angle, min_angle=45, max_angle=315, min_value=0, max_value=100):\n",
    "        \"\"\"Convert angle to gauge reading\"\"\"\n",
    "        # Normalize the angle to the gauge's range\n",
    "        if angle > max_angle:\n",
    "            angle -= 360\n",
    "            \n",
    "        # Calculate reading using linear interpolation\n",
    "        angle_range = max_angle - min_angle\n",
    "        value_range = max_value - min_value\n",
    "        \n",
    "        reading = ((angle - min_angle) / angle_range) * value_range + min_value\n",
    "        return round(reading, 1)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Predict gauge reading from image\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Please train the model first.\")\n",
    "            \n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "            \n",
    "        # Get predictions\n",
    "        results = self.model(image)\n",
    "        \n",
    "        # Initialize variables\n",
    "        center = None\n",
    "        needle_tip = None\n",
    "        gauge_box = None\n",
    "        \n",
    "        # Process predictions\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                # Get class and confidence\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                \n",
    "                if conf > 0.4:  # Confidence threshold\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    \n",
    "                    if cls == 0:  # Center\n",
    "                        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                    elif cls == 1:  # Gauge\n",
    "                        gauge_box = (x1, y1, x2, y2)\n",
    "                    elif cls == 2:  # Needle\n",
    "                        needle_tip = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        \n",
    "        if center and needle_tip:\n",
    "            angle = self.calculate_angle(center, needle_tip)\n",
    "            reading = self.get_reading_from_angle(angle)\n",
    "            \n",
    "            return {\n",
    "                'center': center,\n",
    "                'needle_tip': needle_tip,\n",
    "                'gauge_box': gauge_box,\n",
    "                'angle': angle,\n",
    "                'reading': reading,\n",
    "                'image': image\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def visualize_results(self, results):\n",
    "        \"\"\"Visualize detection results\"\"\"\n",
    "        if results is None:\n",
    "            return None\n",
    "            \n",
    "        output = results['image'].copy()\n",
    "        \n",
    "        if results['gauge_box']:\n",
    "            x1, y1, x2, y2 = results['gauge_box']\n",
    "            cv2.rectangle(output, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        if results['center']:\n",
    "            cv2.circle(output, results['center'], 5, (0, 0, 255), -1)\n",
    "            \n",
    "        if results['needle_tip']:\n",
    "            cv2.circle(output, results['needle_tip'], 5, (255, 0, 0), -1)\n",
    "            cv2.line(output, results['center'], results['needle_tip'], (255, 0, 0), 2)\n",
    "            \n",
    "        # Add text with reading\n",
    "        cv2.putText(output, \n",
    "                   f\"Reading: {results['reading']:.1f}\", \n",
    "                   (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, \n",
    "                   (0, 0, 255), \n",
    "                   2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating dataset paths...\n",
      "Training with dataset config: /home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/updated_data.yaml\n",
      "Ultralytics 8.3.55  Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060, 12030MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/updated_data.yaml, epochs=50, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=gauge_detection, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=gauge_detection/train7\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir gauge_detection/train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/train/labels.cache... 390 images, 0 backgrounds, 0 corrupt: 100%|| 390/390 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/valid/labels.cache... 33 images, 0 backgrounds, 0 corrupt: 100%|| 33/33 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to gauge_detection/train7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mgauge_detection/train7\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.32G     0.8365      2.367      1.124         25        640: 100%|| 25/25 [00:03<00:00,  8.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99          1      0.322      0.332      0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.25G     0.7149        1.1     0.9961         21        640: 100%|| 25/25 [00:02<00:00,  8.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99          1      0.333      0.418      0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.23G     0.7194     0.9488     0.9755         28        640: 100%|| 25/25 [00:02<00:00,  8.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99       0.99      0.327      0.747      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.32G      0.703     0.8613     0.9709         32        640: 100%|| 25/25 [00:02<00:00,  8.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.739       0.76      0.956      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.32G      0.691     0.8071     0.9707         30        640: 100%|| 25/25 [00:02<00:00,  9.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.931      0.876       0.98      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.25G     0.6579      0.739     0.9516         32        640: 100%|| 25/25 [00:02<00:00,  8.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99       0.93      0.963      0.989      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.32G     0.6449     0.7058     0.9451         27        640: 100%|| 25/25 [00:02<00:00,  8.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.889       0.98      0.981      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50       2.3G     0.6493     0.6582     0.9524         29        640: 100%|| 25/25 [00:02<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.976       0.98      0.994      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.32G     0.6346     0.6325     0.9449         23        640: 100%|| 25/25 [00:02<00:00,  9.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.943      0.977      0.983      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.32G     0.6017     0.5778      0.917         40        640: 100%|| 25/25 [00:02<00:00,  9.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.982      0.971      0.983      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.32G     0.5915     0.5571     0.9187         23        640: 100%|| 25/25 [00:02<00:00,  8.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.991       0.98      0.983      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.32G     0.5648     0.5389      0.918         36        640: 100%|| 25/25 [00:02<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99       0.99      0.966      0.975       0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.32G     0.5674     0.5291     0.9153         18        640: 100%|| 25/25 [00:02<00:00,  9.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.983      0.986      0.994      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.32G     0.5467      0.502     0.9072         23        640: 100%|| 25/25 [00:02<00:00,  9.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994       0.99      0.985      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.32G     0.5316     0.4742       0.91         25        640: 100%|| 25/25 [00:02<00:00,  9.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.993       0.98      0.994      0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.33G     0.5383     0.4724     0.9064         25        640: 100%|| 25/25 [00:02<00:00,  8.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.991      0.999      0.995      0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.31G     0.5072     0.4403     0.8898         28        640: 100%|| 25/25 [00:02<00:00,  9.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.991          1      0.995      0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.23G     0.5276     0.4547     0.9073         37        640: 100%|| 25/25 [00:02<00:00,  9.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.981          1      0.995      0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.31G     0.5151     0.4441     0.9022         35        640: 100%|| 25/25 [00:02<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.991      0.997      0.995       0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.29G     0.5107     0.4331     0.8969         30        640: 100%|| 25/25 [00:02<00:00,  9.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.984          1      0.995      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.31G     0.4944     0.4177     0.8872         28        640: 100%|| 25/25 [00:02<00:00,  9.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.992      0.991      0.995      0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.24G     0.5016     0.4194     0.8904         28        640: 100%|| 25/25 [00:02<00:00,  9.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.976      0.991      0.993       0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.31G      0.499     0.4057     0.8942         21        640: 100%|| 25/25 [00:02<00:00,  9.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.31G      0.477     0.3946     0.8808         32        640: 100%|| 25/25 [00:02<00:00,  9.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996      0.997      0.995      0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.31G     0.4748     0.3861     0.8943         44        640: 100%|| 25/25 [00:02<00:00,  9.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.23G     0.4676      0.386     0.8882         20        640: 100%|| 25/25 [00:02<00:00,  9.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.988          1      0.995      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.31G     0.4656     0.3746     0.8822         20        640: 100%|| 25/25 [00:02<00:00,  9.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.992      0.996      0.995       0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.29G     0.4594     0.3599     0.8767         31        640: 100%|| 25/25 [00:02<00:00,  9.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.993          1      0.995      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.31G     0.4554     0.3589     0.8741         21        640: 100%|| 25/25 [00:02<00:00,  9.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.987          1      0.995      0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.24G     0.4523     0.3538     0.8745         25        640: 100%|| 25/25 [00:02<00:00,  9.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.987          1      0.995      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.31G     0.4478     0.3547     0.8725         24        640: 100%|| 25/25 [00:02<00:00,  9.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.991          1      0.995      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.31G     0.4407     0.3492      0.874         34        640: 100%|| 25/25 [00:02<00:00,  9.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.995      0.996      0.995      0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.31G     0.4339     0.3476     0.8798         29        640: 100%|| 25/25 [00:02<00:00,  9.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994      0.997      0.995      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.23G      0.424     0.3338     0.8618         44        640: 100%|| 25/25 [00:02<00:00,  9.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.992          1      0.995      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.32G     0.4113      0.326     0.8693         22        640: 100%|| 25/25 [00:02<00:00,  9.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994          1      0.995      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.31G     0.4212     0.3291     0.8746         26        640: 100%|| 25/25 [00:02<00:00,  9.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996      0.998      0.995      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.31G     0.4048     0.3178     0.8588         32        640: 100%|| 25/25 [00:02<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996      0.999      0.995      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.23G     0.4016     0.3163     0.8671         27        640: 100%|| 25/25 [00:02<00:00,  9.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.992      0.998      0.995      0.868\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.31G     0.3991     0.3139     0.8633         32        640: 100%|| 25/25 [00:02<00:00,  9.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.995          1      0.995      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.31G     0.4016     0.3155     0.8666         27        640: 100%|| 25/25 [00:02<00:00,  9.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.995          1      0.995       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.29G     0.3662     0.2898     0.8167         18        640: 100%|| 25/25 [00:02<00:00,  8.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994      0.999      0.995      0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.21G     0.3625     0.2803     0.8146         18        640: 100%|| 25/25 [00:02<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.992      0.999      0.995      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.27G     0.3603     0.2755     0.8142         18        640: 100%|| 25/25 [00:02<00:00,  9.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994      0.999      0.995      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.29G      0.354       0.27     0.8102         21        640: 100%|| 25/25 [00:02<00:00,  9.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.994      0.998      0.995      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.27G      0.353     0.2636      0.815         18        640: 100%|| 25/25 [00:02<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.995      0.999      0.995      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.27G     0.3523     0.2585     0.8056         18        640: 100%|| 25/25 [00:02<00:00,  9.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.27G     0.3352     0.2573     0.8004         18        640: 100%|| 25/25 [00:02<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.27G     0.3252     0.2481     0.8062         18        640: 100%|| 25/25 [00:02<00:00,  9.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.27G     0.3275     0.2433     0.8029         18        640: 100%|| 25/25 [00:02<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.27G     0.3225     0.2431     0.8035         18        640: 100%|| 25/25 [00:02<00:00,  9.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from gauge_detection/train7/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from gauge_detection/train7/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating gauge_detection/train7/weights/best.pt...\n",
      "Ultralytics 8.3.55  Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060, 12030MiB)\n",
      "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         99      0.996          1      0.995      0.885\n",
      "                Center         33         33          1          1      0.995      0.796\n",
      "                 Gauge         33         33       0.99          1      0.995      0.992\n",
      "                Needle         33         33      0.998          1      0.995      0.868\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mgauge_detection/train7\u001b[0m\n",
      "\n",
      "0: 640x640 2 Centers, 1 Gauge, 1 Needle, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Gauge Reading: 45.7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the gauge reader\n",
    "gauge_reader = GaugeReaderYOLO()\n",
    "\n",
    "# Train the model using your existing YOLO format dataset\n",
    "data_yaml_path = \"/home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/data.yaml\"\n",
    "gauge_reader.train(data_yaml_path, epochs=50)\n",
    "\n",
    "# Make predictions\n",
    "results = gauge_reader.predict('/home/faizal/work/gnprc-domi-app/Model/guage_image.jpg')\n",
    "if results:\n",
    "    # Visualize results\n",
    "    output_image = gauge_reader.visualize_results(results)\n",
    "    cv2.imwrite('result.jpg', output_image)\n",
    "    print(f\"Gauge Reading: {results['reading']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully from: /home/faizal/work/gnprc-domi-app/Model/gauge_detection/train7/weights/best.pt\n",
      "\n",
      "Processing image...\n",
      "Image path: /home/faizal/work/gnprc-domi-app/Model/guage_image.jpg\n",
      "Original image shape: (615, 616, 3)\n",
      "\n",
      "0: 640x640 2 Centers, 1 Gauge, 1 Needle, 4.6ms\n",
      "Speed: 6.2ms preprocess, 4.6ms inference, 150.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "All detections (including low confidence):\n",
      "Detection 1: Gauge - Confidence: 0.951\n",
      "Detection 2: Center - Confidence: 0.865\n",
      "Detection 3: Needle - Confidence: 0.471\n",
      "Detection 4: Center - Confidence: 0.320\n",
      "\n",
      "Detection successful!\n",
      "Gauge Reading: 72.5\n",
      "Angle: 240.68 degrees\n",
      "Results saved to final_result.jpg\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self, model_path):\n",
    "        try:\n",
    "            self.model = YOLO(model_path)\n",
    "            print(f\"Model loaded successfully from: {model_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to load model: {str(e)}\")\n",
    "        \n",
    "    def calculate_angle(self, center, needle_tip):\n",
    "        \"\"\"Calculate angle between vertical line and needle\"\"\"\n",
    "        dx = needle_tip[0] - center[0]\n",
    "        dy = needle_tip[1] - center[1]\n",
    "        angle = math.degrees(math.atan2(dy, dx))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "        return angle\n",
    "\n",
    "    def get_reading_from_angle(self, angle, min_angle=45, max_angle=315, min_value=0, max_value=100):\n",
    "        \"\"\"Convert angle to gauge reading\"\"\"\n",
    "        # Normalize the angle to the gauge's range\n",
    "        if angle > max_angle:\n",
    "            angle -= 360\n",
    "            \n",
    "        # Calculate reading using linear interpolation\n",
    "        angle_range = max_angle - min_angle\n",
    "        value_range = max_value - min_value\n",
    "        \n",
    "        reading = ((angle - min_angle) / angle_range) * value_range + min_value\n",
    "        return round(reading, 1)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Predict gauge reading from image with debug information\"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found at: {image_path}\")\n",
    "            \n",
    "        # Read and debug original image\n",
    "        original_image = cv2.imread(image_path)\n",
    "        if original_image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "        \n",
    "        # Save original image for debugging\n",
    "        cv2.imwrite('debug_original.jpg', original_image)\n",
    "        print(f\"Original image shape: {original_image.shape}\")\n",
    "        \n",
    "        # Get predictions with verbose mode\n",
    "        results = self.model(original_image, verbose=True)\n",
    "        \n",
    "        # Print confidence scores for all detections\n",
    "        print(\"\\nAll detections (including low confidence):\")\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for i, box in enumerate(boxes):\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                class_name = ['Center', 'Gauge', 'Needle'][cls]\n",
    "                print(f\"Detection {i+1}: {class_name} - Confidence: {conf:.3f}\")\n",
    "        \n",
    "        # Initialize variables\n",
    "        center = None\n",
    "        needle_tip = None\n",
    "        gauge_box = None\n",
    "        \n",
    "        # Process predictions with lower confidence threshold for debugging\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                \n",
    "                # Lower confidence threshold for debugging\n",
    "                if conf > 0.3:  # Reduced from 0.5 for debugging\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    \n",
    "                    if cls == 0:  # Center\n",
    "                        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                    elif cls == 1:  # Gauge\n",
    "                        gauge_box = (x1, y1, x2, y2)\n",
    "                    elif cls == 2:  # Needle\n",
    "                        needle_tip = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        \n",
    "        # Create debug visualization\n",
    "        debug_image = original_image.copy()\n",
    "        \n",
    "        # Draw all detections with confidence > 0.3\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                conf = float(box.conf)\n",
    "                if conf > 0.3:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls)\n",
    "                    class_name = ['Center', 'Gauge', 'Needle'][cls]\n",
    "                    color = [(0, 0, 255), (0, 255, 0), (255, 0, 0)][cls]\n",
    "                    \n",
    "                    cv2.rectangle(debug_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(debug_image, \n",
    "                              f\"{class_name}: {conf:.2f}\", \n",
    "                              (x1, y1-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                              0.5, \n",
    "                              color, \n",
    "                              2)\n",
    "        \n",
    "        # Save debug visualization\n",
    "        cv2.imwrite('debug_detections.jpg', debug_image)\n",
    "        \n",
    "        if center and needle_tip:\n",
    "            angle = self.calculate_angle(center, needle_tip)\n",
    "            reading = self.get_reading_from_angle(angle)\n",
    "            \n",
    "            return {\n",
    "                'center': center,\n",
    "                'needle_tip': needle_tip,\n",
    "                'gauge_box': gauge_box,\n",
    "                'angle': angle,\n",
    "                'reading': reading,\n",
    "                'image': original_image\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def visualize_results(self, results):\n",
    "        \"\"\"Visualize detection results\"\"\"\n",
    "        if results is None:\n",
    "            return None\n",
    "            \n",
    "        output = results['image'].copy()\n",
    "        \n",
    "        if results['gauge_box']:\n",
    "            x1, y1, x2, y2 = results['gauge_box']\n",
    "            cv2.rectangle(output, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        if results['center']:\n",
    "            cv2.circle(output, results['center'], 5, (0, 0, 255), -1)\n",
    "            \n",
    "        if results['needle_tip']:\n",
    "            cv2.circle(output, results['needle_tip'], 5, (255, 0, 0), -1)\n",
    "            cv2.line(output, results['center'], results['needle_tip'], (255, 0, 0), 2)\n",
    "            \n",
    "        # Add text with reading\n",
    "        cv2.putText(output, \n",
    "                f\"Reading: {results['reading']:.1f}\", \n",
    "                (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, \n",
    "                (0, 0, 255), \n",
    "                2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Run inference with debug output\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Paths\n",
    "        model_path = \"/home/faizal/work/gnprc-domi-app/Model/gauge_detection/train7/weights/best.pt\"\n",
    "        image_path = \"/home/faizal/work/gnprc-domi-app/Model/guage_image.jpg\"\n",
    "        \n",
    "        # Initialize reader with pre-trained model\n",
    "        print(\"Loading model...\")\n",
    "        reader = GaugeReader(model_path)\n",
    "\n",
    "        print(\"\\nProcessing image...\")\n",
    "        print(f\"Image path: {image_path}\")\n",
    "        results = reader.predict(image_path)\n",
    "\n",
    "        if results is None:\n",
    "            print(\"\\nNo gauge detected with high confidence!\")\n",
    "            print(\"Check debug_original.jpg and debug_detections.jpg for visualization\")\n",
    "        else:\n",
    "            print(\"\\nDetection successful!\")\n",
    "            print(f\"Gauge Reading: {results['reading']:.1f}\")\n",
    "            print(f\"Angle: {results['angle']:.2f} degrees\")\n",
    "            \n",
    "            output_image = reader.visualize_results(results)\n",
    "            cv2.imwrite(\"final_result.jpg\", output_image)\n",
    "            print(\"Results saved to final_result.jpg\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully from: /home/faizal/work/gnprc-domi-app/Model/gauge_detection/train6/weights/best.pt\n",
      "Processing image...\n",
      "\n",
      "0: 640x640 2 Centers, 1 Gauge, 1 Needle, 3.9ms\n",
      "Speed: 2.5ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No gauge detected in the image!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "\n",
    "class GaugeReader:\n",
    "    def __init__(self, model_path):\n",
    "        try:\n",
    "            self.model = YOLO(model_path)\n",
    "            print(f\"Model loaded successfully from: {model_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to load model: {str(e)}\")\n",
    "\n",
    "    def calculate_angle(self, center, needle_tip):\n",
    "        \"\"\"Calculate angle between vertical line and needle\"\"\"\n",
    "        dx = needle_tip[0] - center[0]\n",
    "        dy = needle_tip[1] - center[1]\n",
    "        angle = math.degrees(math.atan2(dy, dx))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "        return angle\n",
    "\n",
    "    def get_reading_from_angle(self, angle, min_angle=45, max_angle=315, min_value=0, max_value=100):\n",
    "        \"\"\"Convert angle to gauge reading\"\"\"\n",
    "        if angle > max_angle:\n",
    "            angle -= 360\n",
    "        \n",
    "        angle_range = max_angle - min_angle\n",
    "        value_range = max_value - min_value\n",
    "        \n",
    "        reading = ((angle - min_angle) / angle_range) * value_range + min_value\n",
    "        return round(reading, 1)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Predict gauge reading from image\"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found at: {image_path}\")\n",
    "            \n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "            \n",
    "        # Get predictions\n",
    "        results = self.model(image)\n",
    "        \n",
    "        # Initialize variables\n",
    "        center = None\n",
    "        needle_tip = None\n",
    "        gauge_box = None\n",
    "        \n",
    "        # Process predictions\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                \n",
    "                if conf > 0.5:  # Confidence threshold\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    \n",
    "                    if cls == 0:  # Center\n",
    "                        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                    elif cls == 1:  # Gauge\n",
    "                        gauge_box = (x1, y1, x2, y2)\n",
    "                    elif cls == 2:  # Needle\n",
    "                        needle_tip = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        \n",
    "        if center and needle_tip:\n",
    "            angle = self.calculate_angle(center, needle_tip)\n",
    "            reading = self.get_reading_from_angle(angle)\n",
    "            \n",
    "            return {\n",
    "                'center': center,\n",
    "                'needle_tip': needle_tip,\n",
    "                'gauge_box': gauge_box,\n",
    "                'angle': angle,\n",
    "                'reading': reading,\n",
    "                'image': image\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def visualize_results(self, results):\n",
    "        \"\"\"Visualize detection results\"\"\"\n",
    "        if results is None:\n",
    "            return None\n",
    "            \n",
    "        output = results['image'].copy()\n",
    "        \n",
    "        if results['gauge_box']:\n",
    "            x1, y1, x2, y2 = results['gauge_box']\n",
    "            cv2.rectangle(output, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        if results['center']:\n",
    "            cv2.circle(output, results['center'], 5, (0, 0, 255), -1)\n",
    "            \n",
    "        if results['needle_tip']:\n",
    "            cv2.circle(output, results['needle_tip'], 5, (255, 0, 0), -1)\n",
    "            cv2.line(output, results['center'], results['needle_tip'], (255, 0, 0), 2)\n",
    "            \n",
    "        cv2.putText(output, \n",
    "                   f\"Reading: {results['reading']:.1f}\", \n",
    "                   (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, \n",
    "                   (0, 0, 255), \n",
    "                   2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Run inference\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Paths\n",
    "        model_path = \"/home/faizal/work/gnprc-domi-app/Model/gauge_detection/train6/weights/best.pt\"\n",
    "        image_path = \"/home/faizal/work/gnprc-domi-app/Model/guage_image.jpg\"\n",
    "        output_path = \"gauge_result.jpg\"\n",
    "\n",
    "        # Initialize reader with pre-trained model\n",
    "        print(\"Loading model...\")\n",
    "        reader = GaugeReader(model_path)\n",
    "\n",
    "        # Make prediction\n",
    "        print(\"Processing image...\")\n",
    "        results = reader.predict(image_path)\n",
    "\n",
    "        if results is None:\n",
    "            print(\"No gauge detected in the image!\")\n",
    "        else:\n",
    "            # Visualize and save results\n",
    "            output_image = reader.visualize_results(results)\n",
    "            cv2.imwrite(output_path, output_image)\n",
    "            \n",
    "            print(\"\\nResults:\")\n",
    "            print(f\"Gauge Reading: {results['reading']:.1f}\")\n",
    "            print(f\"Angle: {results['angle']:.2f} degrees\")\n",
    "            print(f\"Visualization saved to: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnx2tf\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "class YOLOConverter:\n",
    "    def __init__(self, model_path, save_dir='converted_models'):\n",
    "        \"\"\"\n",
    "        Initialize converter with path to trained YOLO model\n",
    "        model_path: Path to YOLOv8 .pt model file\n",
    "        save_dir: Directory to save converted models\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.yolo_model = YOLO(model_path)\n",
    "    \n",
    "    def export_to_onnx(self):\n",
    "        \"\"\"Export YOLOv8 model to ONNX format\"\"\"\n",
    "        print(\"Exporting to ONNX...\")\n",
    "        \n",
    "        # Export to ONNX using ultralytics built-in export\n",
    "        onnx_path = self.save_dir / 'best.onnx'\n",
    "        self.yolo_model.export(format='onnx', \n",
    "                             dynamic=True,\n",
    "                             simplify=True)\n",
    "        \n",
    "        # Move the exported model to our directory\n",
    "        shutil.move('best.onnx', onnx_path)\n",
    "        return str(onnx_path)\n",
    "    \n",
    "    def onnx_to_tf(self, onnx_path):\n",
    "        \"\"\"Convert ONNX model to TensorFlow SavedModel format\"\"\"\n",
    "        print(\"Converting ONNX to TensorFlow...\")\n",
    "        \n",
    "        tf_path = str(self.save_dir / 'tf_model')\n",
    "        \n",
    "        # Convert ONNX to TF using onnx2tf\n",
    "        onnx2tf.convert(\n",
    "            input_onnx_file_path=onnx_path,\n",
    "            output_folder_path=tf_path,\n",
    "            output_signaturedefs=True,\n",
    "            copy_onnx_input_output_names_to_tflite=True\n",
    "        )\n",
    "        \n",
    "        return tf_path\n",
    "    \n",
    "    def optimize_tf_model(self, tf_model_path):\n",
    "        \"\"\"Load and optimize TF model for TFLite conversion\"\"\"\n",
    "        print(\"Optimizing TensorFlow model...\")\n",
    "        \n",
    "        # Load the SavedModel\n",
    "        model = tf.saved_model.load(tf_model_path)\n",
    "        \n",
    "        # Get concrete function\n",
    "        concrete_func = model.signatures['serving_default']\n",
    "        \n",
    "        return concrete_func\n",
    "    \n",
    "    def convert_to_tflite(self, concrete_func, optimization_level='DEFAULT'):\n",
    "        \"\"\"Convert to TFLite with specified optimization\"\"\"\n",
    "        print(f\"Converting to TFLite with {optimization_level} optimization...\")\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "        \n",
    "        # Set optimization config\n",
    "        if optimization_level == 'DEFAULT':\n",
    "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        elif optimization_level == 'LATENCY':\n",
    "            converter.optimizations = [\n",
    "                tf.lite.Optimize.DEFAULT,\n",
    "                tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
    "            ]\n",
    "        elif optimization_level == 'SIZE':\n",
    "            converter.optimizations = [\n",
    "                tf.lite.Optimize.DEFAULT,\n",
    "                tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
    "            ]\n",
    "        \n",
    "        # Enable quantization\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS\n",
    "        ]\n",
    "        \n",
    "        # Convert model\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        # Save model\n",
    "        tflite_path = self.save_dir / 'model.tflite'\n",
    "        tflite_path.write_bytes(tflite_model)\n",
    "        \n",
    "        return str(tflite_path)\n",
    "    \n",
    "    def create_metadata(self, tflite_path):\n",
    "        \"\"\"Add metadata to TFLite model\"\"\"\n",
    "        print(\"Adding metadata...\")\n",
    "        \n",
    "        metadata = {\n",
    "            \"name\": \"GaugeReader\",\n",
    "            \"description\": \"Gauge reading detection model converted from YOLOv8\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"author\": \"Converter\",\n",
    "            \"license\": \"MIT\"\n",
    "        }\n",
    "        \n",
    "        # Create metadata writer\n",
    "        writer = tf.lite.experimental.metadata.writer.MetadataWriter()\n",
    "        \n",
    "        # Add metadata\n",
    "        writer.add_metadata(metadata)\n",
    "        \n",
    "        # Write metadata to model\n",
    "        tflite_with_metadata = writer.populate(tflite_path)\n",
    "        \n",
    "        # Save model with metadata\n",
    "        metadata_path = self.save_dir / 'model_with_metadata.tflite'\n",
    "        metadata_path.write_bytes(tflite_with_metadata)\n",
    "        \n",
    "        return str(metadata_path)\n",
    "    \n",
    "    def verify_tflite_model(self, tflite_path):\n",
    "        \"\"\"Verify TFLite model by running inference\"\"\"\n",
    "        print(\"Verifying TFLite model...\")\n",
    "        \n",
    "        # Load TFLite model\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        \n",
    "        # Get input and output details\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        # Create dummy input\n",
    "        input_shape = input_details[0]['shape']\n",
    "        dummy_input = np.random.random(input_shape).astype(np.float32)\n",
    "        \n",
    "        # Run inference\n",
    "        interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        # Get output\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        print(f\"Model verification successful!\")\n",
    "        print(f\"Input shape: {input_shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def convert(self, optimization_level='DEFAULT'):\n",
    "        \"\"\"Complete conversion pipeline\"\"\"\n",
    "        try:\n",
    "            # Export to ONNX\n",
    "            onnx_path = self.export_to_onnx()\n",
    "            \n",
    "            # Convert ONNX to TF\n",
    "            tf_path = self.onnx_to_tf(onnx_path)\n",
    "            \n",
    "            # Optimize TF model\n",
    "            concrete_func = self.optimize_tf_model(tf_path)\n",
    "            \n",
    "            # Convert to TFLite\n",
    "            tflite_path = self.convert_to_tflite(concrete_func, optimization_level)\n",
    "            \n",
    "            # Add metadata\n",
    "            final_model_path = self.create_metadata(tflite_path)\n",
    "            \n",
    "            # Verify model\n",
    "            self.verify_tflite_model(final_model_path)\n",
    "            \n",
    "            print(f\"\\nConversion complete! Model saved at: {final_model_path}\")\n",
    "            return final_model_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during conversion: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to ONNX...\n",
      "Ultralytics 8.3.55  Python-3.12.3 torch-2.5.1+cu124 CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'gauge_detection/train6/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.45...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  9.4s, saved as 'gauge_detection/train6/weights/best.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (9.6s)\n",
      "Results saved to \u001b[1m/home/faizal/work/gnprc-domi-app/Model/gauge_detection/train6/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=gauge_detection/train6/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=gauge_detection/train6/weights/best.onnx imgsz=640 data=/home/faizal/work/gnprc-domi-app/datasets/Analog_Gauge_Meter.v13-v06-crop.yolov8/updated_data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Error during conversion: [Errno 2] No such file or directory: 'best.onnx'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:886\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 886\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.onnx' -> 'converted_models/best.onnx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m converter \u001b[38;5;241m=\u001b[39m YOLOConverter(model_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert model with desired optimization\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Options: 'DEFAULT', 'LATENCY', or 'SIZE'\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tflite_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimization_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLATENCY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 162\u001b[0m, in \u001b[0;36mYOLOConverter.convert\u001b[0;34m(self, optimization_level)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Complete conversion pipeline\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Export to ONNX\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     onnx_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_to_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Convert ONNX to TF\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     tf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monnx_to_tf(onnx_path)\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mYOLOConverter.export_to_onnx\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myolo_model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     32\u001b[0m                      dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m                      simplify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Move the exported model to our directory\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest.onnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(onnx_path)\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:906\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    904\u001b[0m         rmtree(src)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:475\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.onnx'"
     ]
    }
   ],
   "source": [
    "# After training your YOLO model\n",
    "model_path = 'gauge_detection/train6/weights/best.pt'  # Path to your trained YOLO model\n",
    "\n",
    "# Initialize converter\n",
    "converter = YOLOConverter(model_path)\n",
    "\n",
    "# Convert model with desired optimization\n",
    "# Options: 'DEFAULT', 'LATENCY', or 'SIZE'\n",
    "tflite_model_path = converter.convert(optimization_level='LATENCY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
